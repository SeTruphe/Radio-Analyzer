{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83794607-4ca0-44f2-ad04-399c554b83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import whisper\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import ntpath\n",
    "import shutil\n",
    "from scipy.io import wavfile\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import datetime\n",
    "import datetime\n",
    "import shutil\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "906891ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "recording_path = \"\"\n",
    "ct = datetime.datetime.now()\n",
    "safe_path = path = os.path.expanduser(os.path.join(\"~\", \"radio_analyzer\", str(ct).replace(\":\", \"-\").replace(\" \", \"-\").replace(\".\", \"-\")))\n",
    "os.makedirs(safe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ddf5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create a Audiochunk with start and endtime\n",
    "def splitter(recording: AudioSegment, section_start, section_finish, section_counter, folder_path, format):\n",
    "    working_part = recording[section_start:section_finish]\n",
    "    working_part.export(os.path.join(folder_path, \"{:06d}\".format(section_counter) + \".mp3\"), format=format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f64f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Dropbox\\Studium\\Masterarbeit\\Recordings mit Quellen\\prigoshin\\mp3\\001.mp3\n"
     ]
    }
   ],
   "source": [
    "# Splitt Audiofile in chunks\n",
    "\n",
    "# Get format, load file, create Outputfolder\n",
    "file_format = recording_path.split('.', 1)[1]\n",
    "print(recording_path)\n",
    "recording = AudioSegment.from_file(recording_path, format=recording_path.split('.', 1)[1])\n",
    "\n",
    "# Create Folder for Output\n",
    "name_arg_2 = ntpath.basename(recording_path).split(\".\", 1)[0]\n",
    "tmp = recording_path.split(\"\\\\\")\n",
    "name_arg_1 = tmp[len(tmp) - 3] + \"-\" + tmp[len(tmp) - 2]\n",
    "folder_path = os.path.join(safe_path, name_arg_1 + \"-\" + name_arg_2)\n",
    "\n",
    "# Remove preexisting old files\n",
    "if os.path.exists(folder_path):\n",
    "    shutil.rmtree(folder_path)\n",
    "os.makedirs(folder_path)\n",
    "\n",
    "full_length = len(recording)\n",
    "section_start, section_finish, section_counter = 0, 30000, 1\n",
    "if full_length < section_finish:\n",
    "    print(\"File is to short and needs no splitting\")\n",
    "    recording.export(os.path.join(folder_path, \"{:06d}\".format(section_counter) + \".mp3\"), format=file_format)\n",
    "else:\n",
    "    while section_finish <= full_length:\n",
    "        splitter(recording, section_start, section_finish, section_counter, folder_path, file_format)\n",
    "        section_start = section_finish - 2000\n",
    "        section_finish = section_finish + 28000\n",
    "        section_counter += 1\n",
    "    section_finish = full_length\n",
    "    splitter(recording, section_start, section_finish, section_counter, folder_path, file_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab1a67dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: prigoshin-mp3-001\n",
      "Working on part: 000001.mp3\n",
      "Working on part: 000002.mp3\n",
      "Working on part: 000003.mp3\n",
      "And we are done here :) \n",
      " You can find your files here: C:\\Users\\alatt\\radio_analyzer\\2023-07-06-23-21-29-027576\\prigoshin-mp3-001\n"
     ]
    }
   ],
   "source": [
    "# Transcribe and Translate\n",
    "\"\"\"\n",
    "Sollen die txt files für wer benutzt werden, internal_mode bitte auf true setzen.\n",
    "Das entfernt die Abgrenzungs- und erklärungsstrings.\n",
    "\"\"\"\n",
    "path = folder_path\n",
    "internal_mode = False\n",
    "\n",
    "# Helsinki-nlp\n",
    "tokenizer_helsinki = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
    "model_helsinki = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
    "\n",
    "# Whisper\n",
    "\n",
    "whisper_model = \"large\"\n",
    "\n",
    "filename = path.rsplit(\"\\\\\", 1)[1]\n",
    "print(\"File: \" + filename)\n",
    "\n",
    "text_original = []\n",
    "text_english = []\n",
    "text_german = []\n",
    "\n",
    "if not internal_mode:\n",
    "    text_original.append((\"Model: whisper-\" + whisper_model + \" Task: transcribe\\n\").encode('utf-8'))\n",
    "    text_original.append((\"###START OF ORIGINAL TRANSCRIPTION FROM FILE \" + str(filename) + \"###\").encode('utf-8'))\n",
    "    text_english.append(\"Model: whisper-large-v2 Task: translate original-english\\n\")\n",
    "    text_english.append(\"###START OF ENGLISH TRANSLATION FROM FILE \" + str(filename) + \"###\")\n",
    "    text_german.append(\"Model: Helsinki-nlp Task: translate english-german\\n\")\n",
    "    text_german.append(\"###START OF GERMAN TRANSLATION FROM FILE \" + str(filename) + \"###\")\n",
    "\n",
    "model = whisper.load_model(whisper_model)\n",
    "\n",
    "time_start = 0\n",
    "time_end = 30\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    print(\"Working on part: \" + file)\n",
    "\n",
    "    if not internal_mode:\n",
    "        text_original.append((\"\\n######## START OF \" + str(os.path.basename(file)).upper()\n",
    "                            + \" (\" + str(datetime.timedelta(seconds=time_start)) + \" - \"\n",
    "                            + str(datetime.timedelta(seconds=time_end)) + \"s) \" + \"########\\n\").encode('utf-8'))\n",
    "        text_english.append(\"\\n######## START OF \" + str(os.path.basename(file)).upper()\n",
    "                            + \" (\" + str(datetime.timedelta(seconds=time_start))\n",
    "                            + \" - \" + str(datetime.timedelta(seconds=time_end)) + \"s) \" + \"########\\n\")\n",
    "        text_german.append(\"\\n######## START OF \" + str(os.path.basename(file)).upper()\n",
    "                            + \" (\" + str(datetime.timedelta(seconds=time_start)) + \" - \"\n",
    "                            + str(datetime.timedelta(seconds=time_end)) + \"s) \" + \"########\\n\")\n",
    "        \n",
    "\n",
    "    transcript = model.transcribe(os.path.join(path, file), task=\"transcribe\")[\"text\"].encode('utf-8')\n",
    "    translate = model.transcribe(os.path.join(path, file), task=\"translate\")[\"text\"]\n",
    "\n",
    "    text_original.append(transcript)\n",
    "\n",
    "    text_english.append(translate)\n",
    "\n",
    "    # Helsinki\n",
    "\n",
    "    input_ids_helsinki = tokenizer_helsinki.encode(text_english, return_tensors=\"pt\")\n",
    "    outputs_helsinki = model_helsinki.generate(input_ids_helsinki)\n",
    "    decoded_helsinki = tokenizer_helsinki.decode(outputs_helsinki[0], skip_special_tokens=True)\n",
    "        \n",
    "    text_german.append(decoded_helsinki)\n",
    "\n",
    "    time_start = time_end - 2\n",
    "    time_end = time_start + 30\n",
    "\n",
    "eng_out = [x.encode('utf-8') for x in text_english]\n",
    "deu_out = [x.encode('utf-8') for x in text_german]\n",
    "\n",
    "with open(os.path.join(path, \"translation_english.txt\"), 'wb') as f:\n",
    "    for entry in eng_out:\n",
    "        f.write(entry)\n",
    "f.close()\n",
    "with open(os.path.join(path, \"transcript_original.txt\"), 'wb') as f:\n",
    "    for entry in text_original:\n",
    "        f.write(entry)\n",
    "f.close()\n",
    "with open(os.path.join(path, \"translation_german.txt\"), 'wb') as f:\n",
    "    for entry in deu_out:\n",
    "        f.write(entry)\n",
    "f.close()\n",
    "print(\"And we are done :) \\nYou can find your files here: \" + folder_path )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86450f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
